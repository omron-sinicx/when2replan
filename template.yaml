organization: OMRON SINIC X
twitter: '@omron_sinicx'
title: 'MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics'
conference: IJCAI2020
resources:
  paper: https://arxiv.org/abs/1909.13111
  code: https://github.com/omron-sinicx/multipolar
  video: https://www.youtube.com/embed/adUnIj83RtU
  blog: https://medium.com/sinicx/multipolar-multi-source-policy-aggregation-for-transfer-reinforcement-learning-between-diverse-bc42a152b0f5
description: explore a new challenge in transfer RL, where only a set of source policies collected under unknown diverse dynamics is available for learning a target task efficiently.
image: https://omron-sinicx.github.io/multipolar/assets/teaser.png
url: https://omron-sinicx.github.io/multipolar
speakerdeck: b7a0614c24014dcbbb121fbb9ed234cd
authors:
  - name: Mohammadamin Barekatain*
    affiliation: [1, 2]
    url: http://barekatain.me/
    position: intern
  - name: Ryo Yonetani
    affiliation: [1]
    position: principal investigator
    url: https://yonetaniryo.github.io/
  - name: Masashi Hamaya
    affiliation: [1]
    position: senior researcher
    url: https://sites.google.com/view/masashihamaya/home
    #  - name: Mai Nishimura
    #    affiliation: [1]
    #    url: https://denkiwakame.github.io
    #  - name: Asako Kanezaki
    #    affiliation: [2]
    #    url: https://kanezaki.github.io/
contact_ids: ['github', 'omron', 2] #=> github issues, contact@sinicx.com, 2nd author
affiliations:
  - OMRON SINIC X Corporation
  - Technical University of Munich
meta:
  - '* work done as an intern at OMRON SINIC X.'
bibtex: >
  # arXiv version

  @article{barekatain2019multipolar,
    title={MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics},
    author={Barekatain, Mohammadamin and Yonetani, Ryo and Hamaya, Masashi},
    journal={arXiv preprint arXiv:1909.13111},
    year={2019}
  }

  # IJCAI version

  @inproceedings{barekatain2020multipolar,
    title={MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics},
    author={Barekatain, Mohammadamin and Yonetani, Ryo and Hamaya, Masashi},
    booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
    year={2020}
  }

overview: >
  Transfer reinforcement learning (RL) aims at improving learning efficiency of an agent by exploiting knowledge from other source agents trained on relevant tasks.
  However, it remains challenging to transfer knowledge between different environmental dynamics without having access to the source environments.
  In this work, we explore a new challenge in transfer RL, where only a set of source policies collected under unknown diverse dynamics is available for learning a target task efficiently.
  To address this problem, the proposed approach, MULTI-source POLicy AggRegation (MULTIPOLAR), comprises two key techniques.
  We learn to aggregate the actions provided by the source policies adaptively to maximize the target task performance.
  Meanwhile, we learn an auxiliary network that predicts residuals around the aggregated actions, which ensures the target policy”s expressiveness even when some of the source policies perform poorly.
  We demonstrated the effectiveness of MULTIPOLAR through an extensive experimental evaluation across six simulated environments ranging from classic control problems to challenging robotics simulations, under both continuous and discrete action spaces.

method:
  - title: subsection 1
    image: method.png
    text: >
      **test text with unicode characters:** α, β, φ, ψ
  - title: subsection 2
    image: null
    text: >
      **test text with TeX characters:** $\alpha$, $\beta$, $\phi$, $\psi \\$
      see how it renders with $\KaTeX$.
      $$ E = mc^2$$
      $$ \int \oint \sum \prod $$
      $$ \begin{CD} A @>a>> B \\ @VbVV @AAcA \\ C @= D \end{CD} $$
  - title: null
    image: method.png
    text: >
      subsection body 2

results: null
# results:
#   - This is a result description text.
#   - This is a result1 description text.
#   - This is a result2 description text.
#   - This is a result3 description text.

demo:
  - mp4: result1.mp4
    text: demo text1 demo text1 demo text1
    scale: 100%
  - mp4: result1.mp4
    text: demo text2 demo text2 demo text2
    scale: 100%
  - mp4: result1.mp4
    text: demo text3 demo text3 demo text3
    scale: 80%
